# MIE-1517
Final Project: Attempt to Enhance Mobile-Seed Perception Performance with DAFF Fusion Model

## Project Overview
This project was developed as part of our course requirements and is based on the existing open-source mobile-seed project for mobile robot perception. The original Mobile-Seed project focuses on real-time semantic segmentation and boundary detection in mobile robotics using a lightweight architecture optimized for deployment on embedded devices.

ðŸ”— Original Repository: https://github.com/WHU-USI3DV/Mobile-Seed

If you are interested in the original research and implementation of the seed project, we encourage you to visit the official repository linked above for full details on their methodology, model design, and benchmarks.

Supporting Literature
Our work builds upon and is inspired by the following key publications:

Y. Liao et al., "Mobile-Seed: Joint Semantic Segmentation and Boundary Detection for Mobile Robots," IEEE Robotics and Automation Letters, 2024.
ðŸ“„ Link to paper

L. Tong, K. Qian, and X. Jing, "LBSNet: Lightweight Joint Boundary Detection and Semantic Segmentation for Transparent and Reflective Objects," IEEE Robotics and Automation Letters, vol. 10, no. 2, pp. 955â€“962, Feb. 2025.
DOI: 10.1109/LRA.2024.3518302

These papers provide the theoretical foundation and inspiration for our project's architectural choices and performance evaluation.
